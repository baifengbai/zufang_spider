# zufang_spider
租房信息爬虫,抓取58,赶集,搜房三个网站的租房信息,可自行缩小抓取范围.

程序基于Python 2.7

写着玩的, 所以也没引用什么大型第三方库.功能上,也就处于能凑活用的水准.

配置方法:

1, /Components 目录下三个文件 Site*.py 分别配置self.urlList这个列表. 0 是抓取地址(添加或修改,url里的地名应该都是汉语拼音,或者去网页上copy,把页码换成%s即可); 1 是抓取的最大页数.

2, /Libs/DB.py 修改self.dbAddress, 这是默认数据库的存储地址. 默认数据库是 SQLite3.

3, 进入目录,执行python App.py 即开始抓取. 没条件的本地每天跑一次,有条件的丢vps上crontab加任务.

4, 目前我这里跑了一段日子了,没发现问题.或者说,唯一的问题是....价格涨的我有点儿接受不了.
